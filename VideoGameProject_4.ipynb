{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name', 'Platform', 'Year_of_Release', 'Genre', 'Publisher', 'NA_Sales',\n",
      "       'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales', 'Critic_Score',\n",
      "       'Critic_Count', 'User_Score', 'User_Count', 'Developer', 'Rating'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['Asteroids', '2600', 1980.0, ..., nan, nan, nan],\n",
       "       ['Missile Command', '2600', 1980.0, ..., nan, nan, nan],\n",
       "       ['Kaboom!', '2600', 1980.0, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       ['Mario Tennis', '3DS', 2018.0, ..., nan, nan, nan],\n",
       "       ['Imagine: Makeup Artist', 'DS', 2020.0, ..., nan, 'Ubisoft', 'E'],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]], dtype=object)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#data = pd.read_csv('/Users/elijahjenkins12/Jupiter_Notebooks/datasets/VideoGameData.csv')\n",
    "data = pd.read_csv('/Users/casey ranft/Documents/Casey Ranft/Data Mining/VideoGameData.csv')\n",
    "print(data.columns)\n",
    "data = np.array(data)\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.0\n",
      "[5.]\n"
     ]
    }
   ],
   "source": [
    "#Classifying Data based off critic score\n",
    "\n",
    "\"\"\"\n",
    "Metacritic Score:                 Class:\n",
    "Universal acclaim      -> 90–100  =   5\n",
    "Generally favorable    -> 75–89   =   4\n",
    "Mixed or average       -> 50–74   =   3\n",
    "Generally unfavorable  -> 20–49   =   2\n",
    "Overwhelming dislike   -> 0–19    =   1\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#Array 2 values off from csv\n",
    "criticScore = data[:,10]\n",
    "print(np.nanmax(criticScore)) #need np.nanmax to get max from array with some nan values\n",
    "\n",
    "criticClass = np.zeros((16712,1))\n",
    "\n",
    "for i in range(16712):\n",
    "    #Between 90-100\n",
    "    if (criticScore[i] >= 90 and criticScore[i] <= 100):\n",
    "        criticClass[i] = 5\n",
    "    elif (criticScore[i] >= 75 and criticScore[i] <= 89):\n",
    "        criticClass[i] = 4\n",
    "    elif (criticScore[i] >= 50 and criticScore[i] <= 74):\n",
    "        criticClass[i] = 3\n",
    "    elif (criticScore[i] >= 20 and criticScore[i] <= 49):\n",
    "        criticClass[i] = 2\n",
    "    elif (criticScore[i] >= 0 and criticScore[i] <= 19):\n",
    "        criticClass[i] = 1\n",
    "\n",
    "\n",
    "print(criticClass[728])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numberOfMissingScores(year, array):\n",
    "    nancount = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i in array:\n",
    "        #check how many are missing for CriticScore\n",
    "        if(i == 0):\n",
    "            nancount = nancount + 1\n",
    "        #Calc Total values in interval\n",
    "        total = total + 1\n",
    "    \n",
    "    print(year,\"interval is missing\",nancount,\"CriticScore values out of\",total)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnTarges(scoreArray):\n",
    "    targets = np.zeros((scoreArray.len(),1))\n",
    "    \n",
    "    for i in range(scoreArray.len):\n",
    "        targets[i] = scoreArray[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980 interval is missing 220 CriticScore values out of 222\n"
     ]
    }
   ],
   "source": [
    "interval1 = data[0:222,:] #1980s -> interval1\n",
    "interval1\n",
    "\n",
    "criticScoreArray1= criticClass[0:222]\n",
    "\n",
    "numberOfMissingScores(\"1980\", criticScoreArray1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990-94 interval is missing 279 CriticScore values out of 281\n"
     ]
    }
   ],
   "source": [
    "interval2 = data[222:503,:] #1990-94 -> interval2\n",
    "interval2\n",
    "\n",
    "criticScoreArray2 = criticClass[222:503]\n",
    "\n",
    "numberOfMissingScores(\"1990-94\", criticScoreArray2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1995-99 interval is missing 1403 CriticScore values out of 1497\n"
     ]
    }
   ],
   "source": [
    "interval3 = data[503:2000,:] #1995-99 -> interval3\n",
    "interval3\n",
    "\n",
    "criticScoreArray3 = criticClass[503:2000]\n",
    "\n",
    "numberOfMissingScores(\"1995-99\", criticScoreArray3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-04 interval is missing 966 CriticScore values out of 3256\n"
     ]
    }
   ],
   "source": [
    "interval4 = data[2000:5256,:] #2000-04 -> interval4\n",
    "interval4\n",
    "\n",
    "criticScoreArray4 = criticClass[2000:5256]\n",
    "\n",
    "numberOfMissingScores(\"2000-04\", criticScoreArray4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005-09 interval is missing 2701 CriticScore values out of 6090\n"
     ]
    }
   ],
   "source": [
    "interval5 = data[5256:11346,:] #2005-09 -> interval5\n",
    "interval5\n",
    "\n",
    "criticScoreArray5 = criticClass[5256:11346]\n",
    "\n",
    "numberOfMissingScores(\"2005-09\", criticScoreArray5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-2016 interval is missing 3006 CriticScore values out of 5366\n"
     ]
    }
   ],
   "source": [
    "interval6 = data[11346:16712,:] #2010-2016 -> interval3\n",
    "\n",
    "criticScoreArray6 = criticClass[11346:16712]\n",
    "\n",
    "numberOfMissingScores(\"2010-2016\", criticScoreArray6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5366, 15)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'DS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-2fd7e285853a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \"\"\"\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'DS'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = interval6[:, 1:16]\n",
    "print(X.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, criticScoreArray6, test_size=0.33, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(y_pred)\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
